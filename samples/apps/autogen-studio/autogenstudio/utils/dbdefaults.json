{
  "models": [
    {
      "model": "gpt-4",
      "api_key": "Your Azure API key here",
      "base_url": "Your Azure base URL here",
      "api_type": "azure",
      "api_version": "Your Azure API version here",
      "description": "Azure Open AI model configuration"
    },
    {
      "model": "gpt-4-turbo-preview",
      "description": "OpenAI model configuration"
    },
    {
      "model": "TheBloke/zephyr-7B-alpha-AWQ",
      "api_key": "EMPTY",
      "base_url": "http://localhost:8000/v1",
      "description": "Local model example with vLLM server endpoint"
    }
  ],
  "agents": [
    {
      "type": "userproxy",
      "description": "A user proxy agent that executes code.",
      "config": {
        "name": "userproxy",
        "human_input_mode": "NEVER",
        "max_consecutive_auto_reply": 5,
        "system_message": "You are a helpful assistant.",
        "default_auto_reply": "TERMINATE",
        "llm_config": false,
        "code_execution_config": {
          "work_dir": null,
          "use_docker": false,
          "executor": "commandline-local"
        }
      }
    },
    {
      "type": "assistant",
      "description": "A primary assistant agent that writes plans and code to solve tasks.",
      "skills": [
        {
          "title": "find_papers_arxiv",
          "description": "This skill finds relevant papers on arXiv given a query.",
          "content": "import os\nimport re\nimport json\nimport hashlib\n\n\ndef search_arxiv(query, max_results=10):\n    \"\"\"\n    Searches arXiv for the given query using the arXiv API, then returns the search results. This is a helper function. In most cases, callers will want to use 'find_relevant_papers( query, max_results )' instead.\n\n    Args:\n        query (str): The search query.\n        max_results (int, optional): The maximum number of search results to return. Defaults to 10.\n\n    Returns:\n        jresults (list): A list of dictionaries. Each dictionary contains fields such as 'title', 'authors', 'summary', and 'pdf_url'\n\n    Example:\n        >>> results = search_arxiv(\"attention is all you need\")\n        >>> print(results)\n    \"\"\"\n\n    import arxiv\n\n    key = hashlib.md5((\"search_arxiv(\" + str(max_results) + \")\" + query).encode(\"utf-8\")).hexdigest()\n    # Create the cache if it doesn't exist\n    cache_dir = \".cache\"\n    if not os.path.isdir(cache_dir):\n        os.mkdir(cache_dir)\n\n    fname = os.path.join(cache_dir, key + \".cache\")\n\n    # Cache hit\n    if os.path.isfile(fname):\n        fh = open(fname, \"r\", encoding=\"utf-8\")\n        data = json.loads(fh.read())\n        fh.close()\n        return data\n\n    # Normalize the query, removing operator keywords\n    query = re.sub(r\"[^\\s\\w]\", \" \", query.lower())\n    query = re.sub(r\"\\s(and|or|not)\\s\", \" \", \" \" + query + \" \")\n    query = re.sub(r\"[^\\s\\w]\", \" \", query.lower())\n    query = re.sub(r\"\\s+\", \" \", query).strip()\n\n    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n\n    jresults = list()\n    for result in search.results():\n        r = dict()\n        r[\"entry_id\"] = result.entry_id\n        r[\"updated\"] = str(result.updated)\n        r[\"published\"] = str(result.published)\n        r[\"title\"] = result.title\n        r[\"authors\"] = [str(a) for a in result.authors]\n        r[\"summary\"] = result.summary\n        r[\"comment\"] = result.comment\n        r[\"journal_ref\"] = result.journal_ref\n        r[\"doi\"] = result.doi\n        r[\"primary_category\"] = result.primary_category\n        r[\"categories\"] = result.categories\n        r[\"links\"] = [str(link) for link in result.links]\n        r[\"pdf_url\"] = result.pdf_url\n        jresults.append(r)\n\n    if len(jresults) > max_results:\n        jresults = jresults[0:max_results]\n\n    # Save to cache\n    fh = open(fname, \"w\")\n    fh.write(json.dumps(jresults))\n    fh.close()\n    return jresults\n",
          "file_name": "find_papers_arxiv",
          "examples": ""
        },
        {
          "title": "generate_images",
          "description": "This skill generates images from a given query using OpenAI's DALL-E model and saves them to disk.",
          "content": "from typing import List\nimport uuid\nimport requests  # to perform HTTP requests\nfrom pathlib import Path\n\nfrom openai import OpenAI\n\n\ndef generate_and_save_images(query: str, image_size: str = \"1024x1024\") -> List[str]:\n    \"\"\"\n    Function to paint, draw or illustrate images based on the users query or request. Generates images from a given query using OpenAI's DALL-E model and saves them to disk.  Use the code below anytime there is a request to create an image.\n\n    :param query: A natural language description of the image to be generated.\n    :param image_size: The size of the image to be generated. (default is \"1024x1024\")\n    :return: A list of filenames for the saved images.\n    \"\"\"\n\n    client = OpenAI()  # Initialize the OpenAI client\n    response = client.images.generate(model=\"dall-e-3\", prompt=query, n=1, size=image_size)  # Generate images\n\n    # List to store the file names of saved images\n    saved_files = []\n\n    # Check if the response is successful\n    if response.data:\n        for image_data in response.data:\n            # Generate a random UUID as the file name\n            file_name = str(uuid.uuid4()) + \".png\"  # Assuming the image is a PNG\n            file_path = Path(file_name)\n\n            img_url = image_data.url\n            img_response = requests.get(img_url)\n            if img_response.status_code == 200:\n                # Write the binary content to a file\n                with open(file_path, \"wb\") as img_file:\n                    img_file.write(img_response.content)\n                    print(f\"Image saved to {file_path}\")\n                    saved_files.append(str(file_path))\n            else:\n                print(f\"Failed to download the image from {img_url}\")\n    else:\n        print(\"No image data found in the response!\")\n\n    # Return the list of saved files\n    return saved_files\n\n\n# Example usage of the function:\n# generate_and_save_images(\"A cute baby sea otter\")\n",
          "examples": ""
        }
      ],
      "config": {
        "name": "primary_assistant",
        "llm_config": {
          "config_list": [
            {
              "model": "gpt-4-turbo-preview"
            }
          ],
          "temperature": 0.1,
          "timeout": 600,
          "cache_seed": null
        },
        "human_input_mode": "NEVER",
        "max_consecutive_auto_reply": 8,
        "system_message": "You are a helpful AI assistant. Solve tasks using your coding and language skills. In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute. 1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself. 2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly. Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill. When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user. If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user. If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try. When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible. Reply 'TERMINATE' in the end when everything is done."
      }
    }
  ],
  "skills": [
    {
      "title": "fetch_profile",
      "description": "This skill fetches the text content from a personal website.",
      "content": "from typing import Optional\nimport requests\nfrom bs4 import BeautifulSoup\n\n\ndef fetch_user_profile(url: str) -> Optional[str]:\n    \"\"\"\n    Fetches the text content from a personal website.\n\n    Given a URL of a person's personal website, this function scrapes\n    the content of the page and returns the text found within the <body>.\n\n    Args:\n        url (str): The URL of the person's personal website.\n\n    Returns:\n        Optional[str]: The text content of the website's body, or None if any error occurs.\n    \"\"\"\n    try:\n        # Send a GET request to the URL\n        response = requests.get(url)\n        # Check for successful access to the webpage\n        if response.status_code == 200:\n            # Parse the HTML content of the page using BeautifulSoup\n            soup = BeautifulSoup(response.text, \"html.parser\")\n            # Extract the content of the <body> tag\n            body_content = soup.find(\"body\")\n            # Return all the text in the body tag, stripping leading/trailing whitespaces\n            return \" \".join(body_content.stripped_strings) if body_content else None\n        else:\n            # Return None if the status code isn't 200 (success)\n            return None\n    except requests.RequestException:\n        # Return None if any request-related exception is caught\n        return None\n",
      "examples": "",
      "file_name": "fetch_profile.py"
    },
    {
      "title": "generate_images",
      "description": "This skill generates images from a given query using OpenAI's DALL-E model and saves them to disk.",
      "content": "from typing import List\nimport uuid\nimport requests  # to perform HTTP requests\nfrom pathlib import Path\n\nfrom openai import OpenAI\n\n\ndef generate_and_save_images(query: str, image_size: str = \"1024x1024\") -> List[str]:\n    \"\"\"\n    Function to paint, draw or illustrate images based on the users query or request. Generates images from a given query using OpenAI's DALL-E model and saves them to disk.  Use the code below anytime there is a request to create an image.\n\n    :param query: A natural language description of the image to be generated.\n    :param image_size: The size of the image to be generated. (default is \"1024x1024\")\n    :return: A list of filenames for the saved images.\n    \"\"\"\n\n    client = OpenAI()  # Initialize the OpenAI client\n    response = client.images.generate(model=\"dall-e-3\", prompt=query, n=1, size=image_size)  # Generate images\n\n    # List to store the file names of saved images\n    saved_files = []\n\n    # Check if the response is successful\n    if response.data:\n        for image_data in response.data:\n            # Generate a random UUID as the file name\n            file_name = str(uuid.uuid4()) + \".png\"  # Assuming the image is a PNG\n            file_path = Path(file_name)\n\n            img_url = image_data.url\n            img_response = requests.get(img_url)\n            if img_response.status_code == 200:\n                # Write the binary content to a file\n                with open(file_path, \"wb\") as img_file:\n                    img_file.write(img_response.content)\n                    print(f\"Image saved to {file_path}\")\n                    saved_files.append(str(file_path))\n            else:\n                print(f\"Failed to download the image from {img_url}\")\n    else:\n        print(\"No image data found in the response!\")\n\n    # Return the list of saved files\n    return saved_files\n",
      "examples": "from skills import generate_and_save_images\n\nfilenames = generate_and_save_images(\"A cute baby sea otter\")\nprint(filenames)\n",
      "file_name": "generate_images.py"
    },
    {
      "title": "send_command_to_coding_assistant",
      "description": "Executes various commands through a coding assistant, supporting operations like code management, version control, testing, and more. Designed for versatility in coding tasks.",
      "content": "from typing import Optional\nfrom autogenstudio.codingassistanceservice import CodingAssistantService\n\ndef send_command_to_coding_assistant(\n    assistant_name: str,\n    command: str,\n    args: Optional[str] = None,\n    gh_remote_url: Optional[str] = None,\n    description: Optional[str] = None,\n    private: Optional[bool] = None\n) -> str:\n    \"\"\"\n    Executes commands via a coding assistant. Enables diverse coding operations including reviews, fixes, and version control.\n\n    Args:\n        assistant_name (str): Coding assistant identifier.\n        command (str): Command to execute.\n        args (Optional[str]): Command arguments.\n        gh_remote_url (Optional[str]): GitHub URL for initial setup.\n        description (Optional[str]): Repo description.\n        private (Optional[bool]): Repo privacy setting.\n\n    Returns:\n        str: JSON-formatted command execution result.\n\n    Commands:\n        - 'cmd_clear': Clears console. No args. \n        - 'cmd_ls': Lists directory files. No args.\n        - 'cmd_undo': Undoes last operation. No args.\n        - 'cmd_diff': Shows diffs. No args.\n        - 'cmd_tokens': Displays token usage. No args.\n        - 'get_repo_map': Retrieves repo mapping. No args.\n        - 'cmd_message': \"Review and fix code.\" (natural language query)\n        - 'cmd_git': \"pull\" (git command)\n        - 'cmd_run': \"echo 'Hello'\" (shell command)\n        - 'cmd_pr': \"Feature X implementation\" (PR body)\n        - 'show_file': \"/path/to/file.py\" (file path)\n\n    \"\"\"\n    return CodingAssistantService.send_command_to_coding_assistant(assistant_name, command, args, gh_remote_url, description, private)",
      "examples": "from skills import send_command_to_coding_assistant\n\nresponse = send_command_to_coding_assistant('assistant_name', 'cmd_message', 'Review and fix code.')\nprint(response)\n",
      "file_name": "send_command_to_coding_assistant.py"
    },          
    {
      "title": "fetch_json",
      "description": "Simplifies HTTP GET or POST requests for JSON data retrieval or submission, utilizing AgentService for execution. Ideal for interactions with RESTful APIs.",
      "content": "from autogenstudio.agentservice import AgentService\n\n\ndef fetch_json(url, payload=None, method='GET'):\n    \"\"\"\n    Simplifies fetching or submitting JSON data via HTTP GET or POST, leveraging AgentService. Supports versatile applications in data retrieval or API interactions.\n\n    Args:\n        url (str): Target URL for the JSON data.\n        payload (dict, optional): Payload for POST requests.\n        method (str): 'GET' or 'POST' HTTP method.\n\n    Returns:\n        dict: JSON response as a dictionary.\n\n    Example:\n        # GET data\n        >>> from skills import fetch_json\n        >>> response = fetch_json('https://api.example.com/data')\n        >>> print(response)\n        # POST data\n        >>> from skills import fetch_json\n        >>> response = fetch_json('https://api.example.com/submit', payload={'key': 'value'}, method='POST')\n        >>> print(response)\n    \"\"\"\n    return AgentService.fetch_json(url, payload, method)\n",
      "examples": "from skills import fetch_json\n\n# GET data\nresponse = fetch_json('https://api.example.com/data')\nprint(response)\n\n# POST data\nresponse = fetch_json('https://api.example.com/submit', payload={'key': 'value'}, method='POST')\nprint(response)\n",
      "file_name": "fetch_json.py"
    },
    {
      "title": "upsert_agent",
      "description": "Enables creation or update of an agent, including its name, system message, and description. Suitable for managing agent details and capabilities within the system.",
      "content": "from typing import Optional\nfrom autogenstudio.agentservice import AgentService\n\n\ndef upsert_agent(\n    id: Optional[str] = None,\n    name: Optional[str] = None,\n    msg: Optional[str] = None,\n    description: Optional[str] = None\n) -> str:\n    \"\"\"\n    Manages an agent's configuration by creating a new agent or updating an existing one based on provided identifiers and information.\n\n    Args:\n        id (Optional[str]): Unique ID for the agent (None for new agents).\n        name (Optional[str]): Agent's name.\n        msg (Optional[str]): System message for the agent.\n        description (Optional[str]): Agent's purpose and functionality.\n\n    Returns:\n        JSON string with operation outcome, including updated agent details or an error message.\n    \"\"\"\n    return AgentService.create_or_update_agent(id, name, msg, description)\n",
      "examples": "from skills import upsert_agent\n\nresponse = upsert_agent(id=None, name='Task Assistant', msg='Assist with various tasks.', description='An assistant designed to help with a variety of tasks.')\nprint(response)\n# Success\n{'status': 'true','message': 'Agent upserted successfully','data': [{'type': 'agent_type','config': {'name': 'Agent Name'},'id': 'agent_id_1', 'skills': [{'title': 'Skill Title','id': 'skill_id', 'description': 'Skill Description','file_name': 'skill_file.py'}],'description': 'Agent description'}]}\n",
      "file_name": "upsert_agent.py"
    },
    {
      "title": "manage_agent_skills",
      "description": "Updates an agent's skills by adding or removing them based on specified actions and skill IDs, ensuring the agent's capabilities are accurately maintained. You can discover skills to find which ones to add.",
      "content": "from typing import List\nfrom autogenstudio.agentservice import AgentService\n\ndef manage_agent_skills(agent_id: str, skill_ids: List[str], action: str) -> str:\n    \"\"\"\n    Updates an agent's skill set by adding or removing skills. This function facilitates dynamic skill management for an agent.\n\n    Args:\n        agent_id (str): Identifier of the agent.\n        skill_ids (List[str]): UUIDs of the skills to modify.\n        action (str): 'add' to include or 'remove' to exclude skills.\n\n    Returns:\n        str: JSON string indicating operation success or failure, with agent details or error message.\n    \"\"\"\n    return AgentService.manage_agent_skills(agent_id, skill_ids, action)\n",
      "examples": "from skills import manage_agent_skills\n\n# Add skill\nresponse = manage_agent_skills('123e4567-e89b-12d3-a456-426614174000', ['456e567f-e89c-12d3-a457-426614174000'], 'add')\nprint(response)\n# Success\n{'status': 'true','message': 'Agent upserted successfully','data': [{'type': 'agent_type','config': {'name': 'Agent Name'},'id': 'agent_id_1', 'skills': [{'title': 'Skill Title','id': 'skill_id', 'description': 'Skill Description','file_name': 'skill_file.py'}],'description': 'Agent description'}]}\nprint(response)\n# Remove skill\nresponse = manage_agent_skills('123e4567-e89b-12d3-a456-426614174000', ['789f6780-e89d-12d3-a458-426614174000'], 'remove')\n# Success\n{'status': 'true','message': 'Agent upserted successfully','data': [{'type': 'agent_type','config': {'name': 'Agent Name'},'id': 'agent_id_1', 'skills': [{'title': 'Skill Title','id': 'skill_id', 'description': 'Skill Description','file_name': 'skill_file.py'}],'description': 'Agent description'}]}\n# Error\n{'status': 'false','message': 'Error occurred while upserting agent: <Error Detail>','data': ''}\n",
      "file_name": "manage_agent_skills.py"
    },    
    {
      "title": "discover_skills",
      "description": "Facilitates dynamic discovery of skills using natural language queries. Employs semantic search to identify the most relevant entities, enhancing integration and utilization of new capabilities.",
      "content": "from typing import Dict, List\nfrom autogenstudio.agentservice import AgentService\n\ndef discover_skills(queries: List[str]) -> Dict[str, List[str]]:\n    \"\"\"\n    Utilizes semantic search to match natural language queries with relevant entities. Leverages a semantic search backend to effectively find matches in the specified domain. Only discover if you have to, use context for information before you decide to discover new information.\n\n    Args:\n        queries (List[str]): Natural language queries for entity search.\n\n    Returns:\n        A response object with status, message, and data. The data includes a dictionary mapping queries to lists of processed entities with relevant attributes for skills\n    \"\"\"\n    return AgentService.discover_services('skills', queries)\n",
      "examples": "from skills import discover_skills\n\nresponse = discover_skills(['how to parse JSON', 'image processing with Python'])\nprint(response)\n# Success\n{'status': 'true','message': 'Services discovered successfully','data': {'how to parse JSON': [{'title': 'JSON Parser','skill_id': 'skill_id_1','description': 'Parses JSON data.','file_name': 'json_parser.py'}]}}\n# Error\n{'status': 'false','message': 'Error occurred while discovering services: Invalid service type','data': ''}\n",
      "file_name": "discover_skills.py"
    },
    {
      "title": "discover_agents",
      "description": "Facilitates dynamic discovery of agents using natural language queries. Employs semantic search to identify the most relevant entities, enhancing integration and utilization of new capabilities.",
      "content": "from typing import Dict, List\nfrom autogenstudio.agentservice import AgentService\n\ndef discover_agents(queries: List[str]) -> Dict[str, List[str]]:\n    \"\"\"\n    Utilizes semantic search to match natural language queries with relevant entities. Leverages a semantic search backend to effectively find matches in the specified domain. Only discover if you have to, use context for information before you decide to discover new information.\n\n    Args:\n        queries (List[str]): Natural language queries for entity search.\n\n    Returns:\n        A response object with status, message, and data. The data includes a dictionary mapping queries to lists of processed entities with relevant attributes for agents, including nested skills.\n    \"\"\"\n    return AgentService.discover_services('agents', queries)\n",
      "examples": "from skills import discover_agents\n\nresponse = discover_agents(['task automation', 'data analysis'])\nprint(response)\n# Success\n{'status': 'true','message': 'Services discovered successfully','data': {'task automation': [{'type': 'agent_type','config': {'name': 'Agent Name'},'agent_id': 'agent_id_1', 'skills': [{'title': 'Skill Title','skill_id': 'skill_id', 'description': 'Skill Description','file_name': 'skill_file.py'}],'description': 'Agent description'}]}}\n# Error\n{'status': 'false','message': 'Error occurred while discovering services: Invalid service type','data': ''}\n",
      "file_name": "discover_agents.py"
    },
    {
      "title": "discover_workflows",
      "description": "Facilitates dynamic discovery of workflows using natural language queries. Employs semantic search to identify the most relevant entities, enhancing integration and utilization of new capabilities.",
      "content": "from typing import Dict, List\nfrom autogenstudio.agentservice import AgentService\n\ndef discover_workflows(queries: List[str]) -> Dict[str, List[str]]:\n    \"\"\"\n    Utilizes semantic search to match natural language queries with relevant entities. Leverages a semantic search backend to effectively find matches in the specified domain. Only discover if you have to, use context for information before you decide to discover new information.\n\n    Args:\n        queries (List[str]): Natural language queries for entity search.\n\n    Returns:\n        A response object with status, message, and data. The data includes a dictionary mapping queries to lists of processed entities with relevant attributes for workflows\n\n    Example usage:\n        # Discover workflows\n        >>> from skills import discover_workflows\n        >>> response = discover_workflows(['gaming information', 'travel advising services'])\n        >>> print(response)\n        # Success example: {\"status\": \"true\",\"message\": \"Services discovered successfully\",\"data\": {\"gaming information\": [{\"name\": \"workflow name\",\"type\": \"groupchat\",\"workflow_id\": \"workflow_id_1\",\"summary_method\": \"last\",\"description\": \"Workflow description.\"}]}}\n    \"\"\"\n    return AgentService.discover_services('workflows', queries)\n",
      "examples": "from skills import discover_skills\n\n# Discover skills\nresponse = discover_skills(['how to parse JSON', 'image processing with Python'])\nprint(response)\n# Success\n{'status': 'true','message': 'Services discovered successfully','data': {'how to parse JSON': [{'title': 'JSON Parser','skill_id': 'skill_id_1','description': 'Parses JSON data.','file_name': 'json_parser.py'}]}}\n# Error\n{'status': 'false','message': 'Error occurred while discovering services: Invalid service type','data': ''}\n",
      "file_name": "discover_workflows.py"
    },
    {
      "title": "upsert_skill",
      "description": "This skill facilitates creating or updating a skill within the system. It allows for the specification or modification of a skill's title, content, and file name. The operation updates details of existing skills or initializes new skills based on the provided parameters.",
      "content": "from typing import Optional\nfrom autogenstudio.agentservice import AgentService\n\n\ndef upsert_skill(\n    id: Optional[str] = None,\n    title: Optional[str] = None,\n    content: Optional[str] = None,\n    examples: Optional[str] = None\n    file_name: Optional[str] = None\n) -> str:\n    \"\"\"\n    Creates or updates a skill configuration. If an ID is provided, the skill with that ID is updated; otherwise, a new skill is created.\n\n    Args:\n        id (Optional[str]): The unique identifier for the skill to be updated. For a new skill, this should be None.\n        title (Optional[str]): The title of the skill.\n        content (Optional[str]): The detailed code or instructions that comprise the skill.\n        examples (Optional[str]): Python code examples using the skill. To use the skill doesn't require re-defining it by consuming agent, it needs to be imported from skills ie: 'from skills import read_file'.\n        file_name (Optional[str]): The name of the file associated with the skill.\n        description (Optional[str]): The description of the skill. Used to discover via semantic search, so describe the skill fully.\n\n    Returns:\n        str: A JSON-formatted string indicating the success or failure of the operation. It contains either the details of the updated skill or an error message.\n    \"\"\"\n    return AgentService.create_or_update_skill(id, title, content, examples, file_name, description)\n",
      "examples": "from skills import upsert_skill\n\nresponse = upsert_skill(id=None,title='JSON Parser',content='import json\n\ndef parse_json(data):\n    return json.loads(data)',examples=\"from skills import parse_json\n\nprint(parse_json({}))',file_name='json_parser.py',description='A skill for parsing JSON data.')\"\nprint(response)\n# Success\n{'status': 'true', 'message': 'Skill upserted successfully', 'data': {'id': 'skill_id', 'title': 'JSON Parser', 'file_name': 'json_parser.py', 'description': 'A skill for parsing JSON data.'}}\n# Error\n{'status': 'false', 'message': 'Error occurred while upserting skills: <Error Detail>', 'data': ''}\n",
      "file_name": "upsert_skill.py"
    },
    {
      "title": "get_target_session",
      "description": "Get a target session for a specified workflow, enabling agents to delegate tasks and gather information. Associates and stores any new target session ID against the specified workflow ID/current session ID pair.",
      "content": "from typing import Optional\nfrom autogenstudio.agentservice import AgentService\n\ndef get_target_session(workflow_id: str, current_session_id: str, new_session: Optional[bool] = None) -> str:\n    \"\"\"\n    Gives target session ID based on workflow ID and current session ID. Re-uses any existing session unless new_session is set to True. If omitted and no associated session exists or new_session is True, will create one.\n\n    Args:\n        workflow_id (str): The unique identifier of the workflow for which to give target session.\n        current_session_id (str): The session ID from which the message is sent.\n        new_session (Optional[bool]): Should we create a new session for this workflow? Useful if you want to start a new conversation without existing history.\n\n    Returns:\n        str: JSON response containing the target session ID like {'session_id': <id>} or an error message.\n    \"\"\"\n    return AgentService.get_target_session(workflow_id, current_session_id, new_session)\n",
      "examples":" from skills import get_target_session\n\nresponse = get_target_session('workflow_id_here', 'current_session_id')\nprint(response)\n",
      "file_name": "get_target_session.py"
    },
    {
      "title": "send_message_to_target_session",
      "description": "Sends a message to from a your current session to a desired target session, allowing for continuous communication and task delegation across sessions of workflows and agents.",
      "content": "from autogenstudio.agentservice import AgentService\n\ndef send_message_to_target_session(\n    current_session_id: str,\n    target_session_id: str,\n    message_content: str\n) -> str:\n    \"\"\"\n    Sends a message to an existing target session identified by target_session_id.\n\n    Args:\n        current_session_id (str): The session ID from which the message is sent.\n        target_session_id (str): The session ID of the target session to which the message is sent. If you don't have one you can get one via get_target_session. Carefully look in your context of previous interactions to find the relevant target session to continue a conversation.\n        message_content (str): The content of the message to be sent.\n\n    Returns:\n        str: JSON response from the target session or an error message.\n    \"\"\"\n    return AgentService.send_message_to_target_session(current_session_id, target_session_id, message_content)\n",
      "examples": "from skills import send_message_to_target_session\n\nresponse = send_message_to_target_session('current_session_id_here', 'target_session_id_here', 'Message content here.')\nprint(response)\n",
      "file_name": "send_message_to_target_session.py"
    },
    {
      "title": "web_surf",
      "description": "Enables agents to perform web surfing actions such as informational and navigational searches, visit specific pages, scroll up or down on the current page, answer questions from page content, and summarize web pages.",
      "content": "from typing import Optional\nfrom autogenstudio.websurferservice import WebSurferService\n\nclass WebSurfSkill:\n    def __init__(self, current_session_id: str):\n        \"\"\"Initializes the Web Surf skill with the current session ID for web surfing actions.\"\"\"\n        self.current_session_id = current_session_id\n\n    def informational_search(self, query: str, search_engine: str = 'bing', category: str = 'search') -> str:\n        \"\"\"Performs a web search query and returns the results. Optional filters for search engine and category are available.\n        Args:\n            query (str): The search query to perform.\n            search_engine (str): [Optional] The search engine to use, 'bing' or 'google'. Defaults to 'bing'.\n            category (str): [Optional] The category to filter the search. Options include 'news', 'places', 'images', 'search', 'videos', 'shopping', 'sports', 'events'. Defaults to 'search'.\n        Returns:\n            str: The search results in JSON format.\"\"\"\n        return WebSurferService.informational_search(self.current_session_id, query, search_engine, category)\n\n    def navigational_search(self, query: str, search_engine: str = 'bing', category: str = 'search') -> str:\n        \"\"\"Same as informational_search, conducts a web search query but navigates immediately to the top result, similar to the 'I'm Feeling Lucky' feature.\n        Args:\n            query (str): The search query to perform.\n            search_engine (str): [Optional] Same as informational_search.\n            category (str): [Optional] Same as informational_search.\n        Returns:\n            str: The top search result URL.\"\"\"\n        return WebSurferService.navigational_search(self.current_session_id, query, search_engine, category)\n\n    def visit_page(self, url: str) -> str:\n        \"\"\"Visits a webpage at the given URL and returns its text content.\n        Args:\n            url (str): The URL of the webpage to visit.\n        Returns:\n            str: The text content of the webpage.\"\"\"\n        return WebSurferService.visit_page(self.current_session_id, url)\n\n    def page_up(self) -> str:\n        \"\"\"Scrolls the viewport UP one page-length in the current webpage and returns the new viewport content.\n        Returns:\n            str: The content of the new viewport after scrolling up.\"\"\"\n        return WebSurferService.page_up(self.current_session_id)\n\n    def page_down(self) -> str:\n        \"\"\"Scrolls the viewport DOWN one page-length in the current webpage and returns the new viewport content.\n        Returns:\n            str: The content of the new viewport after scrolling down.\"\"\"\n        return WebSurferService.page_down(self.current_session_id)\n\n    def answer_from_page(self, question: Optional[str] = None, url: Optional[str] = None) -> str:\n        \"\"\"Uses AI to read the page and directly answer a given question based on the content, or summarize the page if no question is provided.\n        Args:\n            question (Optional[str]): The question to answer, defaults to summarizing the current page.\n            url (Optional[str]): The URL of the page, defaults to the current page if not provided.\n        Returns:\n            str: The direct answer or summary of the page content.\"\"\"\n        return WebSurferService.answer_from_page(self.current_session_id, question, url)\n\n    def summarize_page(self, url: Optional[str] = None) -> str:\n        \"\"\"Uses AI to summarize the content found at a given URL or the current page if no URL is provided.\n        Args:\n            url (Optional[str]): The URL of the page to summarize, defaults to the current page if not provided.\n        Returns:\n            str: The summary of the page content.\"\"\"\n        return self.answer_from_page(question=None, url=url)\n",
      "examples": "from skills import WebSurfSkill\n\n# Initialize the web surfing skill with the current session ID\nweb_surf_skill = WebSurfSkill(current_session_id='your-session-id-here')\n\n# Perform an informational search\ninfo_search_results = web_surf_skill.informational_search(query='latest tech news')\nprint(info_search_results)\n\n# Perform a navigational search\nnavigational_result = web_surf_skill.navigational_search(query='OpenAI website')\nprint(navigational_result)\n\n# Visit a specific page\npage_content = web_surf_skill.visit_page(url='https://www.wikipedia.org')\nprint(page_content)\n\n# Scroll up on the current page\npage_up_content = web_surf_skill.page_up()\nprint(page_up_content)\n\n# Scroll down on the current page\npage_down_content = web_surf_skill.page_down()\nprint(page_down_content)\n\n# Answer a question from the current page content\nanswer = web_surf_skill.answer_from_page(question='What is the capital of France?')\nprint(answer)\n\n# Summarize the content of a specific page\nsummary = web_surf_skill.summarize_page(url='https://www.example.com/article')\nprint(summary)\n",
      "file_name": "web_surf.py"
    }
    
  ],
  "workflows": [
    {
      "name": "Travel Agent Group Chat Workflow",
      "description": "A group chat workflow",
      "type": "groupchat",
      "sender": {
        "type": "userproxy",
        "config": {
          "name": "userproxy",
          "human_input_mode": "NEVER",
          "max_consecutive_auto_reply": 5,
          "system_message": "You are a helpful assistant.",
          "code_execution_config": {
            "work_dir": null,
            "use_docker": false,
            "executor": "commandline-local"
          }
        }
      },
      "receiver": {
        "type": "groupchat",
        "config": {
          "name": "group_chat_manager",
          "llm_config": {
            "config_list": [
              {
                "model": "gpt-4-turbo-preview"
              }
            ],
            "temperature": 0.1,
            "timeout": 600,
            "cache_seed": 42
          },
          "human_input_mode": "NEVER",
          "system_message": "Group chat manager"
        },
        "groupchat_config": {
          "admin_name": "Admin",
          "max_round": 10,
          "speaker_selection_method": "auto",
          "agents": [
            {
              "type": "assistant",
              "config": {
                "name": "travel_planner",
                "llm_config": {
                  "config_list": [
                    {
                      "model": "gpt-4-turbo-preview"
                    }
                  ],
                  "temperature": 0.1,
                  "timeout": 600,
                  "cache_seed": 42
                },
                "human_input_mode": "NEVER",
                "max_consecutive_auto_reply": 8,
                "system_message": "You are a helpful assistant that can suggest a travel plan for a user. You are the primary cordinator who will receive suggestions or advice from other agents (local_assistant, language_assistant). You must ensure that the finally plan integrates the suggestions from other agents or team members. YOUR FINAL RESPONSE MUST BE THE COMPLETE PLAN that ends with the word TERMINATE. "
              }
            },
            {
              "type": "assistant",
              "config": {
                "name": "local_assistant",
                "llm_config": {
                  "config_list": [
                    {
                      "model": "gpt-4-turbo-preview"
                    }
                  ],
                  "temperature": 0.1,
                  "timeout": 600,
                  "cache_seed": 42
                },
                "human_input_mode": "NEVER",
                "max_consecutive_auto_reply": 8,
                "system_message": "You are a helpful assistant that can review travel plans, providing critical feedback on how the trip can be enriched for enjoyment of the local culture. If the plan already includes local experiences, you can mention that the plan is satisfactory, with rationale."
              }
            },
            {
              "type": "assistant",
              "config": {
                "name": "language_assistant",
                "llm_config": {
                  "config_list": [
                    {
                      "model": "gpt-4-turbo-preview"
                    }
                  ],
                  "temperature": 0.1,
                  "timeout": 600,
                  "cache_seed": 42
                },
                "human_input_mode": "NEVER",
                "max_consecutive_auto_reply": 8,
                "system_message": "You are a helpful assistant that can review travel plans, providing feedback on important/critical tips about how best to address language or communication challenges for the given destination. If the plan already includes language tips, you can mention that the plan is satisfactory, with rationale."
              }
            }
          ]
        }
      }
    },
    {
      "name": "General Agent Workflow",
      "description": "This workflow is used for general purpose tasks.",
      "sender": {
        "type": "userproxy",
        "description": "A user proxy agent that executes code.",
        "config": {
          "name": "userproxy",
          "human_input_mode": "NEVER",
          "max_consecutive_auto_reply": 10,
          "system_message": "You are a helpful assistant.",
          "default_auto_reply": "TERMINATE",
          "llm_config": false,
          "code_execution_config": {
            "work_dir": null,
            "use_docker": false,
            "executor": "commandline-local"
          }
        }
      },
      "receiver": {
        "type": "assistant",
        "description": "Default assistant to generate plans and write code to solve tasks.",
        "skills": [
          {
            "title": "find_papers_arxiv",
            "description": "This skill finds relevant papers on arXiv given a query.",
            "content": "import os\nimport re\nimport json\nimport hashlib\n\n\ndef search_arxiv(query, max_results=10):\n    \"\"\"\n    Searches arXiv for the given query using the arXiv API, then returns the search results. This is a helper function. In most cases, callers will want to use 'find_relevant_papers( query, max_results )' instead.\n\n    Args:\n        query (str): The search query.\n        max_results (int, optional): The maximum number of search results to return. Defaults to 10.\n\n    Returns:\n        jresults (list): A list of dictionaries. Each dictionary contains fields such as 'title', 'authors', 'summary', and 'pdf_url'\n\n    Example:\n        >>> results = search_arxiv(\"attention is all you need\")\n        >>> print(results)\n    \"\"\"\n\n    import arxiv\n\n    key = hashlib.md5((\"search_arxiv(\" + str(max_results) + \")\" + query).encode(\"utf-8\")).hexdigest()\n    # Create the cache if it doesn't exist\n    cache_dir = \".cache\"\n    if not os.path.isdir(cache_dir):\n        os.mkdir(cache_dir)\n\n    fname = os.path.join(cache_dir, key + \".cache\")\n\n    # Cache hit\n    if os.path.isfile(fname):\n        fh = open(fname, \"r\", encoding=\"utf-8\")\n        data = json.loads(fh.read())\n        fh.close()\n        return data\n\n    # Normalize the query, removing operator keywords\n    query = re.sub(r\"[^\\s\\w]\", \" \", query.lower())\n    query = re.sub(r\"\\s(and|or|not)\\s\", \" \", \" \" + query + \" \")\n    query = re.sub(r\"[^\\s\\w]\", \" \", query.lower())\n    query = re.sub(r\"\\s+\", \" \", query).strip()\n\n    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n\n    jresults = list()\n    for result in search.results():\n        r = dict()\n        r[\"entry_id\"] = result.entry_id\n        r[\"updated\"] = str(result.updated)\n        r[\"published\"] = str(result.published)\n        r[\"title\"] = result.title\n        r[\"authors\"] = [str(a) for a in result.authors]\n        r[\"summary\"] = result.summary\n        r[\"comment\"] = result.comment\n        r[\"journal_ref\"] = result.journal_ref\n        r[\"doi\"] = result.doi\n        r[\"primary_category\"] = result.primary_category\n        r[\"categories\"] = result.categories\n        r[\"links\"] = [str(link) for link in result.links]\n        r[\"pdf_url\"] = result.pdf_url\n        jresults.append(r)\n\n    if len(jresults) > max_results:\n        jresults = jresults[0:max_results]\n\n    # Save to cache\n    fh = open(fname, \"w\")\n    fh.write(json.dumps(jresults))\n    fh.close()\n    return jresults\n",
            "examples": ""
          },
          {
            "title": "generate_images",
            "description": "This skill generates images from a given query using OpenAI's DALL-E model and saves them to disk.",
            "content": "from typing import List\nimport uuid\nimport requests  # to perform HTTP requests\nfrom pathlib import Path\n\nfrom openai import OpenAI\n\n\ndef generate_and_save_images(query: str, image_size: str = \"1024x1024\") -> List[str]:\n    \"\"\"\n    Function to paint, draw or illustrate images based on the users query or request. Generates images from a given query using OpenAI's DALL-E model and saves them to disk.  Use the code below anytime there is a request to create an image.\n\n    :param query: A natural language description of the image to be generated.\n    :param image_size: The size of the image to be generated. (default is \"1024x1024\")\n    :return: A list of filenames for the saved images.\n    \"\"\"\n\n    client = OpenAI()  # Initialize the OpenAI client\n    response = client.images.generate(model=\"dall-e-3\", prompt=query, n=1, size=image_size)  # Generate images\n\n    # List to store the file names of saved images\n    saved_files = []\n\n    # Check if the response is successful\n    if response.data:\n        for image_data in response.data:\n            # Generate a random UUID as the file name\n            file_name = str(uuid.uuid4()) + \".png\"  # Assuming the image is a PNG\n            file_path = Path(file_name)\n\n            img_url = image_data.url\n            img_response = requests.get(img_url)\n            if img_response.status_code == 200:\n                # Write the binary content to a file\n                with open(file_path, \"wb\") as img_file:\n                    img_file.write(img_response.content)\n                    print(f\"Image saved to {file_path}\")\n                    saved_files.append(str(file_path))\n            else:\n                print(f\"Failed to download the image from {img_url}\")\n    else:\n        print(\"No image data found in the response!\")\n\n    # Return the list of saved files\n    return saved_files\n\n\n# Example usage of the function:\n# generate_and_save_images(\"A cute baby sea otter\")\n",
            "examples": ""
          }
        ],
        "config": {
          "name": "primary_assistant",
          "llm_config": {
            "config_list": [
              {
                "model": "gpt-4-1106-preview"
              }
            ],
            "temperature": 0.1,
            "timeout": 600,
            "cache_seed": null
          },
          "human_input_mode": "NEVER",
          "max_consecutive_auto_reply": 15,
          "system_message": "You are a helpful AI assistant. Solve tasks using your coding and language skills. In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute. 1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself. 2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly. Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill. When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user. If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user. If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try. When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible. Reply 'TERMINATE' in the end when everything is done."
        }
      },
      "type": "twoagents"
    }
  ]
}
